{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZ_gU79hZXCD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_data = pd.read_csv(\"./Data/wine.csv\")\n",
    "csv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b478gRzOZaJ6"
   },
   "outputs": [],
   "source": [
    "wine_data = csv_data[[\"alcohol\", \"sugar\", \"pH\"]]\n",
    "wine_target = csv_data[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UgtEH-nZfJW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_target, test_target = train_test_split(wine_data, wine_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaonaFlItRoS"
   },
   "source": [
    "### 랜덤포레스트\n",
    "![](https://www.tibco.com/sites/tibco/files/media_entity/2021-05/random-forest-diagram.svg)\n",
    "\n",
    "랜덤 포레스트는 기능을 무작위로 선택하고 관찰하여 의사 결정 트리의 포레스트를 만든 다음 결과를 평균화합니다.\n",
    "\n",
    "* 랜덤 포레스트의 이점\n",
    "\n",
    "> 상대적 중요성을 측정하기 쉬움\n",
    "해당 기능을 사용하여 해당 포레스트에 있는 모든 트리의 불순물을 줄이는 노드를 보면 기능의 중요성을 쉽게 측정할 수 있습니다.\n",
    "\n",
    "* 다재다능\n",
    "\n",
    "> 랜덤 포레스트는 분류 및 회귀 작업 모두에 사용할 수 있기 때문에 매우 다재다능합니다.\n",
    "\n",
    "* 과적합 없음\n",
    "\n",
    "> 포레스트에 트리가 충분하면 과적합의 위험이 거의 또는 전혀 없습니다.\n",
    "\n",
    "* 높은 정확도\n",
    "\n",
    "> 하위 그룹 간에 상당한 차이가 있는 여러 트리를 사용하면 랜덤 포레스트가 매우 정확한 예측 도구가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dn50MtFbbFY0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import (랜덤포레스트 분류 클래스)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(rf_model, train_data, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kxeIu-Hc2-X"
   },
   "outputs": [],
   "source": [
    "rf_model.fit(train_data, train_target)\n",
    "print(rf_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRoPelUUdG4U"
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "rf_model.fit(train_data, train_target)\n",
    "print(rf_model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxMZM18bru1o"
   },
   "source": [
    "### 엑스트라 트리(extra trees)\n",
    "* 엑스트라 트리는 랜덤 포레스트와 매우 비슷하게 동작\n",
    "* 기본적으로 100개의 결정 트리를 훈련\n",
    "* 전체 특성 중 일부 특성을 랜덤하게 선택해 노드를 분할\n",
    "* 랜덤 포레스트와 엑스트라 트리의 차이점\n",
    "* > 부투스트랩 샘플을 사용하지 않는다는 점\n",
    "* > 각 결정 트리를 만들 때 전체 훈련 세트를 사용\n",
    "* > 노드를 분할 할 때 가장 좋은 분할을 찾는 것이 아니라 무작위로 분할\n",
    "\n",
    "* 하나의 결정 트리에서 특성을 무작위로 분할한다면 성능이 낮아지겠지만 많은 트리를 앙상블 하기 때문에 과대적합을 막고 검증 세트의 점수를 높이는 효과\n",
    "* 보통 엑스트라 트리가 무작위성이 좀 더 커 랜덤 포레스트보다 더 많은 결정 트리를 훈련해야 함\n",
    "* 랜덤하게 노드를 분할하기 때문에 빠른 계산 속도가 엑스트라 트리의 장점\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plOu8b2Vfk9G"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (엑스트라 분류 클래스)\n",
    "\n",
    "et_model = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(et_model, train_data, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQxTsIXlgtPb"
   },
   "outputs": [],
   "source": [
    "et_model.fit(train_data, train_target)\n",
    "print(et_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hh4MlkRtnlh"
   },
   "source": [
    "### 그레디언트 부스팅(gradient boosting)\n",
    "* 그레이디언트 부스팅은 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식\n",
    "\n",
    "* 사이킷런의 GradientBoostingClassifier는 기본적으로 깊이가 3인 결정 트리를 100개 사용\n",
    "\n",
    "* 깊이가 얕은 결정 트리를 사용하기 때문에 과대적합에 강하고 일반적으로 높은 일반화 성능을 기대\n",
    "\n",
    "* 그레이디언트 부스팅은 경사 하강법을 사용. 분류에서는 로지스틱 손실 함수를, 회귀에서는 평균 제곱 오차 함수를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyJDp1Vfg2B6"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (그레디언트 부스팅 분류 클래스)\n",
    "\n",
    "gs_model = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(gs_model, train_data, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRvaC6Bmy89v"
   },
   "outputs": [],
   "source": [
    "gs_model = GradientBoostingClassifier(n_estimators=500, max_depth=1, random_state=42)\n",
    "scores = cross_validate(gs_model, train_data, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s79CjAYXiEXR"
   },
   "outputs": [],
   "source": [
    "gs_model = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
    "scores = cross_validate(gs_model, train_data, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYt27dY6j6OU"
   },
   "outputs": [],
   "source": [
    "gs_model.fit(train_data, train_target)\n",
    "print(gs_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSIWSv_luoVB"
   },
   "source": [
    "### 히스토그램 기반 그레디언트 부스팅(histogram-based gradient boosting)\n",
    "* 히스토그램 기반 그레디언트 부스팅은 정형 데이터를 다루는 머신러닝 알고리즘 중에 가장 인기가 높은 알고리즘\n",
    "\n",
    "* 히스토그램 기반 그레디언트 부스팅은 먼저 입력 특성을 256개의 구간으로 나눈다. 따라서 노드를 분할할 때 최적의 분할을 매우 빠르게 찾을 수 있다.\n",
    "\n",
    "* 히스토그램 기반 그레디언트 부스팅은 256개의 구간 중에서 하나를 떼어 놓고 누락된 값을 위해서 사용. 따라서 입력에 누락된 특성이 있어도 이를 따라 전처리할 필요가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0V1FJxSkJsJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (히스토그램 그레디언트 부스팅 분류 클래스)\n",
    "\n",
    "hgb_model = HistGradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(hgb_model, train_data, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLlgnBtulNNN"
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "hgb_model.fit(train_data, train_target)\n",
    "result = permutation_importance(hgb_model, train_data, train_target, n_repeats=10, random_state=42)\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KCi33mLmuAp"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(random_state=42)\n",
    "scores = cross_validate(model, train_data, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_7Wxa9K3oLZ"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(tree_method=\"hist\", trandom_state=42)\n",
    "scores = cross_validate(model, train_data, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "athDxvx99Ob4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOehi9Kt7mpyHNiMyktkpdg",
   "mount_file_id": "11D2SxJRJOBYxmoeSAevqRT03qYzuYzFD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
